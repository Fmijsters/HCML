{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMSxpJAkqYzk"
   },
   "source": [
    "# Programming Assignment II: Explainability\n",
    "\n",
    "In this assignment you will train machine learning models and experiment with techniques discussed in the lectures.\n",
    "This assignment makes use of existing Python libraries. We have provided links to tutorials/examples if you're not familiar with them yet.\n",
    "\n",
    "\n",
    "All code that you write should be in this notebook. You should submit:\n",
    "* This notebook with your code added. Make sure to add enough documentation.\n",
    "* A short report, max 3 pages including any figures and/or tables. Use this [template](https://www.overleaf.com/read/mvskntycrckw).\n",
    "* Zip the notebook .ipynb and report .pdf files in a file with name format 'Prog_Explainability_Group_[X].zip', where X is your programming group ID (e.g. Prog_Explainability_Group_10.zip). The .ipynb and .pdf files should also have the same name as the zip file.\n",
    "\n",
    "\n",
    "Important notes:\n",
    "* Deadline for this assignment is **Monday June 7, 17:00**. \n",
    "* Send it to both Heysem Kaya (h.kaya@uu.nl) and Yupei Du (y.du@uu.nl), CCing your programming partner.\n",
    "* Title of the email: [INFOMHCML] Explainability programming assignment submission [X], with X the number of your group.\n",
    "* There will be a lab session to assist you with the assignment on **Tuesday, June 1, between 9:00-12:45 over Lab Channel in Teams**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyaViIx8WzS"
   },
   "source": [
    "## Installation\n",
    "\n",
    "For this assignment, we are going to use the following Python packages:\n",
    "\n",
    "matplotlib, pandas, statsmodels, interpret, scikit-learn, openpyxl and graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6EaC6P7RqXOh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Installing packages\n",
    "!conda install python-graphviz\n",
    "!pip install matplotlib pandas statsmodels interpret sklearn openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSC0_WEpY0k"
   },
   "source": [
    "## Downloading the data\n",
    "We are going to use the combined cycle power plant dataset. This dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. We have the following features: hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V). We will train ML models to predict the net hourly electrical energy output (EP) of the plant.\n",
    "\n",
    "For a detailed description, see: [[Description](https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant)]\n",
    "\n",
    "We first need to download and prepare data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fleSmPrE7UMT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "unzip:  cannot find or open CCPP.zip, CCPP.zip.zip or CCPP.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# Download and unzip data\n",
    "!wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00294/CCPP.zip\n",
    "!unzip CCPP.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQpW5C3Sg9YA"
   },
   "source": [
    "## Loading and preprocessing the data\n",
    "We split the data into training (first 5000 instances) and validation (the subsequent 2000) and test (the last 2568) sets. We will use the training set to train a model, and validation set to optimize the model hyper-parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JycjPmn_7p41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x000002B91A9A1620>\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap>\", line 177, in cb\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bf4e83c67f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load and prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolynomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mctypeslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\site-packages\\numpy\\polynomial\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \"\"\"\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpolynomial\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolynomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mchebyshev\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChebyshev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlegendre\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLegendre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\site-packages\\numpy\\polynomial\\polynomial.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolyutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_polybase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mABCPolyBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mpolytrim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrimcoef\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fmijs\\anaconda3\\envs\\aif360\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# global variables\n",
    "DATA_FILENAME = 'CCPP/Folds5x2_pp.xlsx'\n",
    "FEATURE_NAMES = ['AT', 'V', 'AP', 'RH']\n",
    "LABEL_NAME = 'PE'\n",
    "# Load the data from the excel file\n",
    "def load_data():\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set[FEATURE_NAMES]\n",
    "        labels = data_set[LABEL_NAME]\n",
    "        return features, labels\n",
    "\n",
    "    data = pd.read_excel(DATA_FILENAME)\n",
    "    train_set, dev_set, test_set = data[:5000], data[5000: 7000], data[7000:]\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    dev_features, dev_labels = split_feature_label(dev_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n",
    "\n",
    "# preprocess (by z-normalization) the data for the regression task\n",
    "# return the normalized feature sets and corresponding target variables \n",
    "def prepare_load_regression_data():\n",
    "    train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels = load_data()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(train_features)\n",
    "    train_features = pd.DataFrame(data=scaler.transform(train_features), columns=FEATURE_NAMES)\n",
    "    dev_features = pd.DataFrame(data=scaler.transform(dev_features), columns=FEATURE_NAMES)\n",
    "    test_features = pd.DataFrame(data=scaler.transform(test_features), columns=FEATURE_NAMES)\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels\n",
    "\n",
    "# binarize the data for the classification task\n",
    "# return the discretized feature sets and corresponding target variables \n",
    "def prepare_load_classification_data():\n",
    "    train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels = load_data()\n",
    "    feature_mean, label_mean = train_features.mean(axis=0), train_labels.mean(axis=0)\n",
    "\n",
    "    train_features = pd.DataFrame(data=np.where(train_features > feature_mean, 1, 0), columns=FEATURE_NAMES)\n",
    "    dev_features = pd.DataFrame(data=np.where(dev_features > feature_mean, 1, 0), columns=FEATURE_NAMES)\n",
    "    test_features = pd.DataFrame(data=np.where(test_features > feature_mean, 1, 0), columns=FEATURE_NAMES)\n",
    "    train_labels = pd.DataFrame(data=np.where(train_labels > label_mean, 1, 0), columns=[LABEL_NAME])\n",
    "    dev_labels = pd.DataFrame(data=np.where(dev_labels > label_mean, 1, 0), columns=[LABEL_NAME])\n",
    "    test_labels = pd.DataFrame(data=np.where(test_labels > label_mean, 1, 0), columns=[LABEL_NAME])\n",
    "\n",
    "    return train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QabF2JOdMTI4"
   },
   "source": [
    "## Training and Interpreting a Linear Regression Model\n",
    "\n",
    "**Q1**. Train a linear regression model (we recommend the statsmodels package) and report $R^2$ (goodness of fit) statistic. \n",
    "\n",
    "For model interpretability, provide for each feature (+ the bias variable) the following in tabular format: \n",
    "* Weight estimates\n",
    "* SE (standard error of estimates) \n",
    "* T statistics \n",
    "\n",
    "\n",
    "Further Questions regarding the linear model (to be included in the report): \n",
    "\n",
    "**Q2**. Which three features are the most important?\n",
    "\n",
    "**Q3**. How does the gas turbine energy yield (EP) change with unit (one degree C) increase of the ambient temperature given that all other feature values remain the same?\n",
    "\n",
    "**Q4**. Visualize the weight estimates using 95% confidence intervals.\n",
    "\n",
    "**Q5**. Show bar graph illustrations of the feature effects for the first two validation set instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B91BszFhMStw"
   },
   "outputs": [],
   "source": [
    "# We recommend the statsmodels package\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tj6Pri4HBeO"
   },
   "source": [
    "**Q6.** Reflection: why would training a regression tree not work well for this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiv5chyDOfxS"
   },
   "source": [
    "## Training and Interpreting Classification Models\n",
    "Using the preprocessing function implemented above to prepare the dataset for  the classification task. This function simply binarizes all variables including the target variable (EP) using the respective training set mean as threshold. A value of 1 means a high value vs 0 a low(er than average) value. Note that we do the feature binarization to ease interpretation of the models, normally that is not necessary for classification models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7r09mMfeo2k"
   },
   "source": [
    "### Training and Interpreting EBM\n",
    "Train a Explainable Boosting Machine (with [interpret.ml](https://github.com/interpretml/interpret/))\n",
    "\n",
    "For a tutorial see: [[Tutorial](https://nbviewer.jupyter.org/github/interpretml/interpret/blob/master/examples/python/notebooks/Interpretable%20Classification%20Methods.ipynb)]\n",
    "\n",
    "**Q7**. Report (global) feature importances for EBM as a table or figure. What are the most important three features in EBM? Are they the same as in the linear model? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-ZmqpxweoZv"
   },
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "# EBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7dAwTIfbsc"
   },
   "source": [
    "### Training and Explaining Neural Networks\n",
    "Train two Neural Networks:\n",
    "1. One-layer MLP (ReLU activation function + 50 hidden neurons)\n",
    "2. Two-layer MLP (ReLU activation function + (20, 20) hidden neurons)\n",
    "\n",
    "We recommend to use the Adam optimizer. Fine-tune the learning rate and any other hyper-parameters you find necessary. \n",
    "\n",
    "For a tutorial see: [[Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQjg_qtCf_WD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# One-layer MLP\n",
    "\n",
    "# Two-layer MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpGv6J6XlBQ4"
   },
   "source": [
    "You can check the tutorials for SHAP and LIME explanations for neural networks \n",
    "[[SHAP Tutorial](https://nbviewer.jupyter.org/github/interpretml/interpret/blob/master/examples/python/notebooks/Explaining%20Blackbox%20Classifiers.ipynb)] \n",
    "[[LIME Tutorial](https://nbviewer.jupyter.org/github/interpretml/interpret/blob/master/examples/python/notebooks/Explaining%20Blackbox%20Classifiers.ipynb)]\n",
    "\n",
    "\n",
    "**Q8**. Provide explanations for randomly selected three test set instances using two explanation methods (LIME and SHAP) with two NN models  (namely the single-hidden layer NN model and the two-hidden-layer NN model: 2 x 2 x 3 = 12 explanations in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIo-o_lClJYQ"
   },
   "outputs": [],
   "source": [
    "# Global explanations\n",
    "import graphviz\n",
    "from interpret import show\n",
    "\n",
    "# Local explanations (SHAP and LIME)\n",
    "from interpret.blackbox import LimeTabular\n",
    "from interpret.blackbox import ShapKernel"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of programming_assignment_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
